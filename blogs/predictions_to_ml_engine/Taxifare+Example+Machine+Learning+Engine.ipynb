{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup constants and globals.\n",
    "import os\n",
    "PROJECT = 'predictions-api-to-cloud-ml'       # CHANGE THIS\n",
    "REGION = 'us-west1-a'                         # CHANGE THIS\n",
    "STORAGE_BUCKET = 'papi-bucket'                # CHANGE THIS\n",
    "TRAINING_DATA_FILE = 'sample/train.csv'       # CHANGE THIS\n",
    "VALIDATION_DATA_FILE = 'sample/valid.csv'     # CHANGE THIS\n",
    "SCHEMA_FILE = 'sample/taxifare.json'          # CHANGE THIS\n",
    "TAXIFARE_REGRESSION_MODEL_ID = 'taxifare_regression'\n",
    "TRAINING_DATA_FILE_BUCKET_LOCATION = 'gs://' + STORAGE_BUCKET + '/' + TRAINING_DATA_FILE\n",
    "EVAL_DATA_FILE_BUCKET_LOCATION = 'gs://' + STORAGE_BUCKET + '/' + VALIDATION_DATA_FILE\n",
    "SCHEMA_FILE_BUCKET_LOCATION = 'gs://' + STORAGE_BUCKET + '/' + SCHEMA_FILE\n",
    "OUTDIR = 'gs://' + STORAGE_BUCKET + '/'\n",
    "PREPROCESSING = 'preprocessing'\n",
    "PREPROCESSING_DIR = OUTDIR + PREPROCESSING\n",
    "TRAINING = 'training'\n",
    "TRAINING_DIR = OUTDIR + TRAINING\n",
    "FEATURES_FILE = PREPROCESSING_DIR + '/features.json'\n",
    "TRAINING_REGION = 'us-central1' # This has to be one of [us-central1, us-east1, europe-west1, asia-east1] apparently.\n",
    "SCALE_TIER = 'STANDARD_1'\n",
    "VERSION_NAME = 'v1'\n",
    "\n",
    "# for bash\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "hiddenCell": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project=predictions-api-to-cloud-ml\n",
      "region=us-west1-a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "echo \"project=$PROJECT\"\n",
    "echo \"region=$REGION\"\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "hiddenCell": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cml 0.1.9.1-alpha\n",
      "sd 1.0.0\n",
      "tf 1.0.0\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libs.\n",
    "import google.datalab.ml as ml\n",
    "import google.datalab.storage as storage\n",
    "import json\n",
    "import mltoolbox.regression.linear as sd\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "print('sd ' + str(sd.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup storage bucket for Machine Learning Engine and empty preprocessing directory.\n",
    "BUCKET = storage.Bucket(STORAGE_BUCKET)\n",
    "for preprocessing_obj in BUCKET.objects(prefix=PREPROCESSING):\n",
    "    preprocessing_obj.delete()\n",
    "# Read all files in preprocessing folder within the bucket.\n",
    "for preprocessing_obj in BUCKET.objects(prefix=PREPROCESSING):\n",
    "    print preprocessing_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track BigQuery status at\n",
      "https://bigquery.cloud.google.com/queries/predictions-api-to-cloud-ml\n",
      "Running numerical analysis...done.\n",
      "Running categorical analysis...done.\n",
      "Analyze: completed\n"
     ]
    }
   ],
   "source": [
    "# Initialize training and evaluation data sets and analyze training data for the model in Machine Learning Engine.\n",
    "train_csv = ml.CsvDataSet(\n",
    "  file_pattern=TRAINING_DATA_FILE_BUCKET_LOCATION,\n",
    "  schema_file=SCHEMA_FILE_BUCKET_LOCATION)\n",
    "eval_csv = ml.CsvDataSet(\n",
    "  file_pattern=EVAL_DATA_FILE_BUCKET_LOCATION,\n",
    "  schema_file=SCHEMA_FILE_BUCKET_LOCATION)\n",
    "sd.analyze(\n",
    "  dataset=train_csv,\n",
    "  output_dir=PREPROCESSING_DIR,\n",
    "  cloud=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create feature transformations for the model in Machine Learning Engine.\n",
    "features = {\n",
    "  \"fare_amount\": {\"transform\": \"target\"},\n",
    "  \"key\": {\"transform\": \"key\"}, \n",
    "  \"dayofweek\": {\"transform\": \"one_hot\"},\n",
    "  \"hourofday\": {\"transform\": \"embedding\", \"embedding_dim\": 2}, # group-combine the hour\n",
    "}\n",
    "file_io.write_string_to_file(FEATURES_FILE, json.dumps(features, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Cloud Storage Object gs://papi-bucket/preprocessing/features.json\n",
      "Google Cloud Storage Object gs://papi-bucket/preprocessing/schema.json\n",
      "Google Cloud Storage Object gs://papi-bucket/preprocessing/stats.json\n",
      "Google Cloud Storage Object gs://papi-bucket/preprocessing/vocab_dayofweek.csv\n",
      "Google Cloud Storage Object gs://papi-bucket/preprocessing/vocab_hourofday.csv\n",
      "Google Cloud Storage Object gs://papi-bucket/preprocessing/vocab_key.csv\n"
     ]
    }
   ],
   "source": [
    "# Read all files in preprocessing folder within the bucket.\n",
    "for preprocessing_obj in BUCKET.objects(prefix=PREPROCESSING):\n",
    "    print preprocessing_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Empty training directory to prepare for training.\n",
    "for training_obj in BUCKET.objects(prefix=TRAINING):\n",
    "    training_obj.delete()\n",
    "# Read all files in training folder within the bucket.\n",
    "for training_obj in BUCKET.objects(prefix=TRAINING):\n",
    "    print training_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building package and uploading to gs://papi-bucket/training/staging/trainer.tar.gz\n",
      "Job request send. View status of job at\n",
      "https://console.developers.google.com/ml/jobs?project=predictions-api-to-cloud-ml\n"
     ]
    }
   ],
   "source": [
    "# Train new model in Machine Learning Engine.\n",
    "TRAINING_CONFIG = ml.CloudTrainingConfig(region=TRAINING_REGION, scale_tier=SCALE_TIER)\n",
    "sd.train(\n",
    "  train_dataset=train_csv,\n",
    "  eval_dataset=eval_csv,\n",
    "  features=features,\n",
    "  analysis_dir=PREPROCESSING_DIR,\n",
    "  output_dir=TRAINING_DIR,\n",
    "  max_steps=2500,\n",
    "  cloud=TRAINING_CONFIG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Cloud Storage Object gs://papi-bucket/training/\n",
      "Google Cloud Storage Object gs://papi-bucket/training/evaluation_model/\n",
      "Google Cloud Storage Object gs://papi-bucket/training/evaluation_model/assets.extra/\n",
      "Google Cloud Storage Object gs://papi-bucket/training/evaluation_model/assets.extra/features.json\n",
      "Google Cloud Storage Object gs://papi-bucket/training/evaluation_model/assets.extra/schema.json\n",
      "Google Cloud Storage Object gs://papi-bucket/training/evaluation_model/saved_model.pb\n",
      "Google Cloud Storage Object gs://papi-bucket/training/evaluation_model/variables/\n",
      "Google Cloud Storage Object gs://papi-bucket/training/evaluation_model/variables/variables.data-00000-of-00001\n",
      "Google Cloud Storage Object gs://papi-bucket/training/evaluation_model/variables/variables.index\n",
      "Google Cloud Storage Object gs://papi-bucket/training/features_file.json\n",
      "Google Cloud Storage Object gs://papi-bucket/training/model/\n",
      "Google Cloud Storage Object gs://papi-bucket/training/model/assets.extra/\n",
      "Google Cloud Storage Object gs://papi-bucket/training/model/assets.extra/features.json\n",
      "Google Cloud Storage Object gs://papi-bucket/training/model/assets.extra/schema.json\n",
      "Google Cloud Storage Object gs://papi-bucket/training/model/saved_model.pb\n",
      "Google Cloud Storage Object gs://papi-bucket/training/model/variables/\n",
      "Google Cloud Storage Object gs://papi-bucket/training/model/variables/variables.data-00000-of-00001\n",
      "Google Cloud Storage Object gs://papi-bucket/training/model/variables/variables.index\n",
      "Google Cloud Storage Object gs://papi-bucket/training/staging/trainer.tar.gz\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/checkpoint\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/eval/\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/eval/events.out.tfevents.1490119971.master-ae9bc12559-0-nttqb\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/eval/events.out.tfevents.1490120005.master-ae9bc12559-0-nttqb\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/events.out.tfevents.1490119940.master-ae9bc12559-0-nttqb\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/intermediate_evaluation_models/\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/intermediate_evaluation_models/1490120008185/\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/intermediate_evaluation_models/1490120008185/assets.extra/\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/intermediate_evaluation_models/1490120008185/assets.extra/features.json\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/intermediate_evaluation_models/1490120008185/assets.extra/schema.json\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/intermediate_evaluation_models/1490120008185/saved_model.pb\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/intermediate_evaluation_models/1490120008185/variables/\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/intermediate_evaluation_models/1490120008185/variables/variables.data-00000-of-00001\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/intermediate_evaluation_models/1490120008185/variables/variables.index\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/intermediate_prediction_models/\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/intermediate_prediction_models/1490120031435/\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/intermediate_prediction_models/1490120031435/assets.extra/\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/intermediate_prediction_models/1490120031435/assets.extra/features.json\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/intermediate_prediction_models/1490120031435/assets.extra/schema.json\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/intermediate_prediction_models/1490120031435/saved_model.pb\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/intermediate_prediction_models/1490120031435/variables/\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/intermediate_prediction_models/1490120031435/variables/variables.data-00000-of-00001\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/export/intermediate_prediction_models/1490120031435/variables/variables.index\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/graph.pbtxt\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/model.ckpt-0.data-00000-of-00003\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/model.ckpt-0.data-00001-of-00003\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/model.ckpt-0.data-00002-of-00003\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/model.ckpt-0.index\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/model.ckpt-0.meta\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/model.ckpt-2504.data-00000-of-00003\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/model.ckpt-2504.data-00001-of-00003\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/model.ckpt-2504.data-00002-of-00003\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/model.ckpt-2504.index\n",
      "Google Cloud Storage Object gs://papi-bucket/training/train/model.ckpt-2504.meta\n"
     ]
    }
   ],
   "source": [
    "# Read all files in training folder within the bucket.\n",
    "for training_obj in BUCKET.objects(prefix=TRAINING):\n",
    "    print training_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'trainingOutput': {u'consumedMLUnits': 1.67}, u'trainingInput': {u'scaleTier': u'STANDARD_1', u'region': u'us-central1', u'args': [u'--train-data-paths=gs://papi-bucket/sample/train.csv', u'--eval-data-paths=gs://papi-bucket/sample/valid.csv', u'--preprocess-output-dir=gs://papi-bucket/preprocessing', u'--transforms-file=gs://papi-bucket/training/features_file.json', u'--model-type=linear_regression', u'--max-steps=2500', u'--train-batch-size=100', u'--eval-batch-size=16', u'--min-eval-frequency=100', u'--learning-rate=0.01', u'--epsilon=0.0005'], u'pythonModule': u'mltoolbox._structured_data.trainer.task', u'jobDir': u'gs://papi-bucket/training', u'packageUris': [u'gs://papi-bucket/training/staging/trainer.tar.gz', u'gs://cloud-datalab/deploy/tf/tensorflow-1.0.0-cp27-cp27mu-manylinux1_x86_64.whl', u'gs://cloud-datalab/deploy/tf/protobuf-3.1.0-py2.py3-none-any.whl']}, u'jobId': u'mltoolbox_regression_linear_170321_180125', u'state': u'SUCCEEDED', u'startTime': u'2017-03-21T18:12:44Z', u'endTime': u'2017-03-21T18:14:30Z', u'createTime': u'2017-03-21T18:01:26Z'}\n",
      "{u'trainingOutput': {u'consumedMLUnits': 1.67}, u'trainingInput': {u'scaleTier': u'STANDARD_1', u'region': u'us-central1', u'args': [u'--train-data-paths=gs://papi-bucket/sample/train.csv', u'--eval-data-paths=gs://papi-bucket/sample/valid.csv', u'--preprocess-output-dir=gs://papi-bucket/preprocessing', u'--transforms-file=gs://papi-bucket/training/features_file.json', u'--model-type=dnn_regression', u'--max-steps=2500', u'--train-batch-size=100', u'--eval-batch-size=16', u'--min-eval-frequency=100', u'--learning-rate=0.01', u'--epsilon=0.0005', u'--layer-size1=64', u'--layer-size2=4'], u'pythonModule': u'mltoolbox._structured_data.trainer.task', u'jobDir': u'gs://papi-bucket/training', u'packageUris': [u'gs://papi-bucket/training/staging/trainer.tar.gz', u'gs://cloud-datalab/deploy/tf/tensorflow-1.0.0-cp27-cp27mu-manylinux1_x86_64.whl', u'gs://cloud-datalab/deploy/tf/protobuf-3.1.0-py2.py3-none-any.whl']}, u'jobId': u'mltoolbox_regression_dnn_170321_160723', u'state': u'SUCCEEDED', u'startTime': u'2017-03-21T16:13:42Z', u'endTime': u'2017-03-21T16:17:43Z', u'createTime': u'2017-03-21T16:07:25Z'}\n"
     ]
    }
   ],
   "source": [
    "# List current ML jobs.\n",
    "for job in ml.Jobs().get_iterator():\n",
    "    print job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation \"projects/predictions-api-to-cloud-ml/operations/delete_model_taxifare_regression-1490190644\"\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Delete the model in Machine Learning Engine in case it was created previously.\n",
    "ml.Models().delete(model_name=TAXIFARE_REGRESSION_MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation \"projects/predictions-api-to-cloud-ml/operations/create_taxifare_regression_v1-1490190693190\"\n"
     ]
    }
   ],
   "source": [
    "# Deploy the model in Machine Learning Engine (create a model object for it and push the training binary into the object).\n",
    "ml.Models().create(model_name=TAXIFARE_REGRESSION_MODEL_ID)\n",
    "ml.ModelVersions(model_name=TAXIFARE_REGRESSION_MODEL_ID).deploy(version_name=VERSION_NAME, path=TRAINING_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'regions': [u'us-central1'], u'defaultVersion': {u'deploymentUri': u'gs://papi-bucket/training/model', u'name': u'projects/predictions-api-to-cloud-ml/models/taxifare_regression/versions/v1', u'isDefault': True, u'createTime': u'2017-03-22T13:51:33Z'}, u'name': u'projects/predictions-api-to-cloud-ml/models/taxifare_regression'}\n"
     ]
    }
   ],
   "source": [
    "# List current ML models.\n",
    "for model in ml.Models().get_iterator():\n",
    "    print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-06-01 00:48:00.000000-73.984740.769340.72...</td>\n",
       "      <td>9.82895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-06-01 00:48:00.000000-74.006940.7440.7734...</td>\n",
       "      <td>9.82887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-06-02 00:48:00.000000-73.977340.779440.77...</td>\n",
       "      <td>9.96345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-06-03 00:48:00.000000-73.971440.794440.74...</td>\n",
       "      <td>10.2289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-06-04 00:48:00.000000-73.997640.763940.75...</td>\n",
       "      <td>9.73902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2009-06-05 00:48:00.000000-74.004540.742240.77...</td>\n",
       "      <td>10.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012-06-15 00:46:17.000000-74.000640.737340.69...</td>\n",
       "      <td>9.99913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2009-06-06 00:48:00.000000-73.995440.721140.71...</td>\n",
       "      <td>9.49842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009-06-06 00:48:00.000000-73.94540.779240.766...</td>\n",
       "      <td>9.49971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 key predicted\n",
       "0  2009-06-01 00:48:00.000000-73.984740.769340.72...   9.82895\n",
       "1  2009-06-01 00:48:00.000000-74.006940.7440.7734...   9.82887\n",
       "2  2009-06-02 00:48:00.000000-73.977340.779440.77...   9.96345\n",
       "3  2009-06-03 00:48:00.000000-73.971440.794440.74...   10.2289\n",
       "4  2009-06-04 00:48:00.000000-73.997640.763940.75...   9.73902\n",
       "5  2009-06-05 00:48:00.000000-74.004540.742240.77...   10.0021\n",
       "6  2012-06-15 00:46:17.000000-74.000640.737340.69...   9.99913\n",
       "7  2009-06-06 00:48:00.000000-73.995440.721140.71...   9.49842\n",
       "8  2009-06-06 00:48:00.000000-73.94540.779240.766...   9.49971"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions from new model in Machine Learning Engine.\n",
    "csv_format_predictions_input = [\n",
    "  'Mon,0,-73.984685,40.769262,-73.991065,40.728145,3.0,2009-06-01 00:48:00.000000-73.984740.769340.7281-73.9911',\n",
    "  'Mon,0,-74.006927,40.739993,-73.950025,40.773403,3.0,2009-06-01 00:48:00.000000-74.006940.7440.7734-73.95',\n",
    "  'Tue,0,-73.977345,40.779387,-73.97615,40.778867,3.0,2009-06-02 00:48:00.000000-73.977340.779440.7789-73.9762',\n",
    "  'Wed,0,-73.97136,40.794413,-73.99623,40.74524,3.0,2009-06-03 00:48:00.000000-73.971440.794440.7452-73.9962',\n",
    "  'Thu,0,-73.997642,40.763853,-73.99485,40.750282,3.0,2009-06-04 00:48:00.000000-73.997640.763940.7503-73.9948',\n",
    "  'Fri,0,-74.004538,40.742202,-73.955823,40.773485,3.0,2009-06-05 00:48:00.000000-74.004540.742240.7735-73.9558',\n",
    "  'Fri,0,-74.000589,40.73731,-73.985902,40.692725,3.0,2012-06-15 00:46:17.000000-74.000640.737340.6927-73.9859',\n",
    "  'Sat,0,-73.995432,40.72114,-73.992403,40.719745,3.0,2009-06-06 00:48:00.000000-73.995440.721140.7197-73.9924',\n",
    "  'Sat,0,-73.945033,40.779203,-73.952037,40.766802,3.0,2009-06-06 00:48:00.000000-73.94540.779240.7668-73.952',\n",
    "]\n",
    "sd.predict(\n",
    "  data=csv_format_predictions_input,\n",
    "  model_name=TAXIFARE_REGRESSION_MODEL_ID,\n",
    "  model_version=VERSION_NAME,\n",
    "  cloud=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
